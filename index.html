<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Use the Force, Luke!</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link rel="stylesheet" href="vendor/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="vendor/simple-line-icons/css/simple-line-icons.css">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli" rel="stylesheet">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="device-mockups/device-mockups.min.css">

    <!-- Custom styles for this template -->
    <link href="css/new-age.min.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <section class="features" id="projects">
      <div class="container">
        <div class="section-heading text-center">
          <h2>Use the Force Luke! <br> Learning to Predict Physical Forces by Simulating Effects </h2>
          <h3> K Ehsani, S Tulsiani, S Gupta, A Farhadi, A Gupta (CVPR'20)</h3>
          <br><br>
          <img src="img/teaser_force.jpg"  style="border-radius: 25px; align-content: center; width:850pt;">
          <hr>
        </div>
        <div class="row">
          <div class="col-lg-12 my-auto">
            <div class="container-fluid">
              <div class="row">
                <h4>
                  When we humans look at a video of human-object interaction, we can not only infer what is happening but we can even extract actionable information and imitate those interactions. On the other hand, current recognition or geometric approaches lack the physicality of action representation. In this paper, we take a step towards more physical understanding of actions. We address the problem of inferring contact points and the physical forces from videos of humans interacting with objects.  One of the main challenges in tackling this problem is obtaining ground-truth labels for forces. We sidestep this problem by instead using a physics simulator for supervision.  Specifically, we use a simulator to  predict  effects,  and  enforce  that  estimated  forces  must lead to same effect as depicted in the video.
                </h4> 
                <h4>
                   Our quantitative and qualitative results show that:
                  <ol>
                    <li> We can predict meaningful forces from videos whose effects lead to accurate imitation of the motions observe.
                    </li>
                    <li> 
                      By jointly optimizing for contact point and force prediction, we can improve the performance on both tasks in comparison to independent training.
                    </li>
                    <li> 
                      We can learn a representation from this model that generalizes to novel objects using few shot examples.
                    </li>
                  </ol>
                </h4>
               
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

  

 

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/new-age.min.js"></script>

  </body>

</html>
